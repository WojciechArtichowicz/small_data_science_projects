{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(openxlsx)\n",
    "library(ggplot2)\n",
    "library(tidyverse)\n",
    "library(kernlab)\n",
    "library(caret)\n",
    "library(gridExtra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Conc</th><th scope=col>SA</th><th scope=col>V</th><th scope=col>SA/V</th><th scope=col>Th-SC</th><th scope=col>Th-Ep</th><th scope=col>Th-T</th><th scope=col>Fol-Den</th><th scope=col>Fol-Dia</th><th scope=col>Enh</th><th scope=col>Kow</th><th scope=col>ConAng</th><th scope=col>Kow-sw</th><th scope=col>ConAng-sw</th><th scope=col>LayerQ</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>15.8547179</td><td> 1256.637 </td><td>  4188.790</td><td>0.3000000 </td><td>15.0      </td><td>67.5      </td><td>2.48      </td><td>264.8     </td><td> 97       </td><td>0         </td><td> 0.00     </td><td> 72       </td><td>0         </td><td>1         </td><td>A         </td></tr>\n",
       "\t<tr><td> 0.1268377</td><td>31415.927 </td><td>523598.776</td><td>0.0600000 </td><td>15.0      </td><td>67.5      </td><td>2.48      </td><td>264.8     </td><td> 97       </td><td>0         </td><td> 0.00     </td><td> 72       </td><td>0         </td><td>1         </td><td>A         </td></tr>\n",
       "\t<tr><td> 3.9636795</td><td> 3298.672 </td><td> 41887.902</td><td>0.0787500 </td><td>17.8      </td><td>61.1      </td><td>2.54      </td><td> 11.0     </td><td>200       </td><td>0         </td><td> 0.00     </td><td> 72       </td><td>0         </td><td>1         </td><td>A         </td></tr>\n",
       "\t<tr><td> 1.2737978</td><td> 3769.911 </td><td> 15707.963</td><td>0.2400000 </td><td>17.8      </td><td>61.1      </td><td>2.54      </td><td> 11.0     </td><td>117       </td><td>0         </td><td> 0.00     </td><td> 25       </td><td>0         </td><td>1         </td><td>B         </td></tr>\n",
       "\t<tr><td> 9.4000000</td><td> 4300.840 </td><td> 26521.849</td><td>0.1621622 </td><td> 8.9      </td><td>28.6      </td><td>0.70      </td><td>365.5     </td><td> 36       </td><td>0         </td><td>-1.16     </td><td>  0       </td><td>1         </td><td>0         </td><td>B         </td></tr>\n",
       "\t<tr><td>18.0413267</td><td> 2123.717 </td><td>  9202.772</td><td>0.2307692 </td><td>17.8      </td><td>61.1      </td><td>2.54      </td><td> 11.0     </td><td>117       </td><td>0         </td><td> 0.00     </td><td>139       </td><td>0         </td><td>1         </td><td>B         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " Conc & SA & V & SA/V & Th-SC & Th-Ep & Th-T & Fol-Den & Fol-Dia & Enh & Kow & ConAng & Kow-sw & ConAng-sw & LayerQ\\\\\n",
       "\\hline\n",
       "\t 15.8547179 &  1256.637  &   4188.790 & 0.3000000  & 15.0       & 67.5       & 2.48       & 264.8      &  97        & 0          &  0.00      &  72        & 0          & 1          & A         \\\\\n",
       "\t  0.1268377 & 31415.927  & 523598.776 & 0.0600000  & 15.0       & 67.5       & 2.48       & 264.8      &  97        & 0          &  0.00      &  72        & 0          & 1          & A         \\\\\n",
       "\t  3.9636795 &  3298.672  &  41887.902 & 0.0787500  & 17.8       & 61.1       & 2.54       &  11.0      & 200        & 0          &  0.00      &  72        & 0          & 1          & A         \\\\\n",
       "\t  1.2737978 &  3769.911  &  15707.963 & 0.2400000  & 17.8       & 61.1       & 2.54       &  11.0      & 117        & 0          &  0.00      &  25        & 0          & 1          & B         \\\\\n",
       "\t  9.4000000 &  4300.840  &  26521.849 & 0.1621622  &  8.9       & 28.6       & 0.70       & 365.5      &  36        & 0          & -1.16      &   0        & 1          & 0          & B         \\\\\n",
       "\t 18.0413267 &  2123.717  &   9202.772 & 0.2307692  & 17.8       & 61.1       & 2.54       &  11.0      & 117        & 0          &  0.00      & 139        & 0          & 1          & B         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Conc | SA | V | SA/V | Th-SC | Th-Ep | Th-T | Fol-Den | Fol-Dia | Enh | Kow | ConAng | Kow-sw | ConAng-sw | LayerQ |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 15.8547179 |  1256.637  |   4188.790 | 0.3000000  | 15.0       | 67.5       | 2.48       | 264.8      |  97        | 0          |  0.00      |  72        | 0          | 1          | A          |\n",
       "|  0.1268377 | 31415.927  | 523598.776 | 0.0600000  | 15.0       | 67.5       | 2.48       | 264.8      |  97        | 0          |  0.00      |  72        | 0          | 1          | A          |\n",
       "|  3.9636795 |  3298.672  |  41887.902 | 0.0787500  | 17.8       | 61.1       | 2.54       |  11.0      | 200        | 0          |  0.00      |  72        | 0          | 1          | A          |\n",
       "|  1.2737978 |  3769.911  |  15707.963 | 0.2400000  | 17.8       | 61.1       | 2.54       |  11.0      | 117        | 0          |  0.00      |  25        | 0          | 1          | B          |\n",
       "|  9.4000000 |  4300.840  |  26521.849 | 0.1621622  |  8.9       | 28.6       | 0.70       | 365.5      |  36        | 0          | -1.16      |   0        | 1          | 0          | B          |\n",
       "| 18.0413267 |  2123.717  |   9202.772 | 0.2307692  | 17.8       | 61.1       | 2.54       |  11.0      | 117        | 0          |  0.00      | 139        | 0          | 1          | B          |\n",
       "\n"
      ],
      "text/plain": [
       "  Conc       SA        V          SA/V      Th-SC Th-Ep Th-T Fol-Den Fol-Dia\n",
       "1 15.8547179  1256.637   4188.790 0.3000000 15.0  67.5  2.48 264.8    97    \n",
       "2  0.1268377 31415.927 523598.776 0.0600000 15.0  67.5  2.48 264.8    97    \n",
       "3  3.9636795  3298.672  41887.902 0.0787500 17.8  61.1  2.54  11.0   200    \n",
       "4  1.2737978  3769.911  15707.963 0.2400000 17.8  61.1  2.54  11.0   117    \n",
       "5  9.4000000  4300.840  26521.849 0.1621622  8.9  28.6  0.70 365.5    36    \n",
       "6 18.0413267  2123.717   9202.772 0.2307692 17.8  61.1  2.54  11.0   117    \n",
       "  Enh Kow   ConAng Kow-sw ConAng-sw LayerQ\n",
       "1 0    0.00  72    0      1         A     \n",
       "2 0    0.00  72    0      1         A     \n",
       "3 0    0.00  72    0      1         A     \n",
       "4 0    0.00  25    0      1         B     \n",
       "5 0   -1.16   0    1      0         B     \n",
       "6 0    0.00 139    0      1         B     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Conc</th><th scope=col>SA</th><th scope=col>V</th><th scope=col>SA/V</th><th scope=col>Th-SC</th><th scope=col>Th-Ep</th><th scope=col>Th-T</th><th scope=col>Fol-Den</th><th scope=col>Fol-Dia</th><th scope=col>Enh</th><th scope=col>Kow</th><th scope=col>ConAng</th><th scope=col>Kow-sw</th><th scope=col>ConAng-sw</th><th scope=col>LayerQ</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1.268377e-01</td><td>31415.92654 </td><td>523598.77560</td><td>0.0600000   </td><td>15.00000    </td><td>67.50000    </td><td>2.48000     </td><td>264.8000    </td><td> 97         </td><td>0           </td><td> 0.000      </td><td>72          </td><td>0           </td><td>1           </td><td>A           </td></tr>\n",
       "\t<tr><td>1.283477e-07</td><td> 1256.63706 </td><td>  4188.79020</td><td>0.3000000   </td><td>17.82125    </td><td>61.10000    </td><td>2.54742     </td><td> 11.0000    </td><td>117         </td><td>0           </td><td> 0.000      </td><td>75          </td><td>0           </td><td>1           </td><td>A           </td></tr>\n",
       "\t<tr><td>1.189104e+01</td><td> 1256.63706 </td><td>  4188.79020</td><td>0.3000000   </td><td>15.58889    </td><td>67.54286    </td><td>2.48000     </td><td>264.8333    </td><td> 97         </td><td>0           </td><td> 0.000      </td><td>72          </td><td>0           </td><td>1           </td><td>B           </td></tr>\n",
       "\t<tr><td>9.131662e-04</td><td>   78.53982 </td><td>    65.44985</td><td>1.2000000   </td><td>15.58889    </td><td>67.54286    </td><td>2.48000     </td><td>264.8333    </td><td> 97         </td><td>0           </td><td> 0.000      </td><td>63          </td><td>0           </td><td>1           </td><td>B           </td></tr>\n",
       "\t<tr><td>8.000000e-01</td><td>  153.93804 </td><td>   179.59438</td><td>0.8571429   </td><td>15.60000    </td><td>67.50000    </td><td>2.48000     </td><td>264.8000    </td><td> 97         </td><td>0           </td><td>-0.075      </td><td> 0          </td><td>1           </td><td>0           </td><td>B           </td></tr>\n",
       "\t<tr><td>8.067738e+00</td><td> 3631.68111 </td><td> 20579.52628</td><td>0.1764706   </td><td>17.80000    </td><td>61.10000    </td><td>2.54000     </td><td> 11.0000    </td><td>117         </td><td>0           </td><td> 0.000      </td><td>90          </td><td>0           </td><td>1           </td><td>B           </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " Conc & SA & V & SA/V & Th-SC & Th-Ep & Th-T & Fol-Den & Fol-Dia & Enh & Kow & ConAng & Kow-sw & ConAng-sw & LayerQ\\\\\n",
       "\\hline\n",
       "\t 1.268377e-01 & 31415.92654  & 523598.77560 & 0.0600000    & 15.00000     & 67.50000     & 2.48000      & 264.8000     &  97          & 0            &  0.000       & 72           & 0            & 1            & A           \\\\\n",
       "\t 1.283477e-07 &  1256.63706  &   4188.79020 & 0.3000000    & 17.82125     & 61.10000     & 2.54742      &  11.0000     & 117          & 0            &  0.000       & 75           & 0            & 1            & A           \\\\\n",
       "\t 1.189104e+01 &  1256.63706  &   4188.79020 & 0.3000000    & 15.58889     & 67.54286     & 2.48000      & 264.8333     &  97          & 0            &  0.000       & 72           & 0            & 1            & B           \\\\\n",
       "\t 9.131662e-04 &    78.53982  &     65.44985 & 1.2000000    & 15.58889     & 67.54286     & 2.48000      & 264.8333     &  97          & 0            &  0.000       & 63           & 0            & 1            & B           \\\\\n",
       "\t 8.000000e-01 &   153.93804  &    179.59438 & 0.8571429    & 15.60000     & 67.50000     & 2.48000      & 264.8000     &  97          & 0            & -0.075       &  0           & 1            & 0            & B           \\\\\n",
       "\t 8.067738e+00 &  3631.68111  &  20579.52628 & 0.1764706    & 17.80000     & 61.10000     & 2.54000      &  11.0000     & 117          & 0            &  0.000       & 90           & 0            & 1            & B           \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Conc | SA | V | SA/V | Th-SC | Th-Ep | Th-T | Fol-Den | Fol-Dia | Enh | Kow | ConAng | Kow-sw | ConAng-sw | LayerQ |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1.268377e-01 | 31415.92654  | 523598.77560 | 0.0600000    | 15.00000     | 67.50000     | 2.48000      | 264.8000     |  97          | 0            |  0.000       | 72           | 0            | 1            | A            |\n",
       "| 1.283477e-07 |  1256.63706  |   4188.79020 | 0.3000000    | 17.82125     | 61.10000     | 2.54742      |  11.0000     | 117          | 0            |  0.000       | 75           | 0            | 1            | A            |\n",
       "| 1.189104e+01 |  1256.63706  |   4188.79020 | 0.3000000    | 15.58889     | 67.54286     | 2.48000      | 264.8333     |  97          | 0            |  0.000       | 72           | 0            | 1            | B            |\n",
       "| 9.131662e-04 |    78.53982  |     65.44985 | 1.2000000    | 15.58889     | 67.54286     | 2.48000      | 264.8333     |  97          | 0            |  0.000       | 63           | 0            | 1            | B            |\n",
       "| 8.000000e-01 |   153.93804  |    179.59438 | 0.8571429    | 15.60000     | 67.50000     | 2.48000      | 264.8000     |  97          | 0            | -0.075       |  0           | 1            | 0            | B            |\n",
       "| 8.067738e+00 |  3631.68111  |  20579.52628 | 0.1764706    | 17.80000     | 61.10000     | 2.54000      |  11.0000     | 117          | 0            |  0.000       | 90           | 0            | 1            | B            |\n",
       "\n"
      ],
      "text/plain": [
       "  Conc         SA          V            SA/V      Th-SC    Th-Ep    Th-T   \n",
       "1 1.268377e-01 31415.92654 523598.77560 0.0600000 15.00000 67.50000 2.48000\n",
       "2 1.283477e-07  1256.63706   4188.79020 0.3000000 17.82125 61.10000 2.54742\n",
       "3 1.189104e+01  1256.63706   4188.79020 0.3000000 15.58889 67.54286 2.48000\n",
       "4 9.131662e-04    78.53982     65.44985 1.2000000 15.58889 67.54286 2.48000\n",
       "5 8.000000e-01   153.93804    179.59438 0.8571429 15.60000 67.50000 2.48000\n",
       "6 8.067738e+00  3631.68111  20579.52628 0.1764706 17.80000 61.10000 2.54000\n",
       "  Fol-Den  Fol-Dia Enh Kow    ConAng Kow-sw ConAng-sw LayerQ\n",
       "1 264.8000  97     0    0.000 72     0      1         A     \n",
       "2  11.0000 117     0    0.000 75     0      1         A     \n",
       "3 264.8333  97     0    0.000 72     0      1         B     \n",
       "4 264.8333  97     0    0.000 63     0      1         B     \n",
       "5 264.8000  97     0   -0.075  0     1      0         B     \n",
       "6  11.0000 117     0    0.000 90     0      1         B     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Conc</th><th scope=col>SA</th><th scope=col>V</th><th scope=col>SA/V</th><th scope=col>Th-SC</th><th scope=col>Th-Ep</th><th scope=col>Th-T</th><th scope=col>Fol-Den</th><th scope=col>Fol-Dia</th><th scope=col>Enh</th><th scope=col>Kow</th><th scope=col>ConAng</th><th scope=col>Kow-sw</th><th scope=col>ConAng-sw</th><th scope=col>LayerQ</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 7.3957868 </td><td>3848.4510  </td><td>22449.29750</td><td>0.1714286  </td><td>17.80000   </td><td>61.10000   </td><td>2.54       </td><td> 11.0000   </td><td>200        </td><td>0          </td><td> 0.00      </td><td> 72        </td><td>0          </td><td>1          </td><td>A          </td></tr>\n",
       "\t<tr><td>33.5190452 </td><td> 706.8583  </td><td> 1767.14587</td><td>0.4000000  </td><td>15.58889   </td><td>67.54286   </td><td>2.48       </td><td>264.8333   </td><td> 97        </td><td>0          </td><td> 0.00      </td><td>151        </td><td>0          </td><td>1          </td><td>B          </td></tr>\n",
       "\t<tr><td>10.0000000 </td><td>4901.6699  </td><td>32269.32709</td><td>0.1518987  </td><td>17.82000   </td><td>61.10000   </td><td>2.54       </td><td> 11.0000   </td><td>117        </td><td>0          </td><td>-1.16      </td><td>  0        </td><td>1          </td><td>0          </td><td>B          </td></tr>\n",
       "\t<tr><td> 1.0000000 </td><td>  66.4761  </td><td>   50.96501</td><td>1.3043478  </td><td>16.60000   </td><td>32.00000   </td><td>2.09       </td><td>289.0000   </td><td> 25        </td><td>0          </td><td>-1.16      </td><td>  0        </td><td>1          </td><td>0          </td><td>B          </td></tr>\n",
       "\t<tr><td> 2.5367549 </td><td>7853.9816  </td><td>65449.84695</td><td>0.1200000  </td><td>17.80000   </td><td>61.10000   </td><td>2.54       </td><td> 11.0000   </td><td>117        </td><td>0          </td><td> 0.00      </td><td> 72        </td><td>0          </td><td>1          </td><td>B          </td></tr>\n",
       "\t<tr><td> 0.5661324 </td><td>6126.1057  </td><td>35342.91735</td><td>0.1733333  </td><td>17.80000   </td><td>61.10000   </td><td>2.54       </td><td> 11.0000   </td><td>117        </td><td>0          </td><td> 0.00      </td><td> 25        </td><td>0          </td><td>1          </td><td>B          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " Conc & SA & V & SA/V & Th-SC & Th-Ep & Th-T & Fol-Den & Fol-Dia & Enh & Kow & ConAng & Kow-sw & ConAng-sw & LayerQ\\\\\n",
       "\\hline\n",
       "\t  7.3957868  & 3848.4510   & 22449.29750 & 0.1714286   & 17.80000    & 61.10000    & 2.54        &  11.0000    & 200         & 0           &  0.00       &  72         & 0           & 1           & A          \\\\\n",
       "\t 33.5190452  &  706.8583   &  1767.14587 & 0.4000000   & 15.58889    & 67.54286    & 2.48        & 264.8333    &  97         & 0           &  0.00       & 151         & 0           & 1           & B          \\\\\n",
       "\t 10.0000000  & 4901.6699   & 32269.32709 & 0.1518987   & 17.82000    & 61.10000    & 2.54        &  11.0000    & 117         & 0           & -1.16       &   0         & 1           & 0           & B          \\\\\n",
       "\t  1.0000000  &   66.4761   &    50.96501 & 1.3043478   & 16.60000    & 32.00000    & 2.09        & 289.0000    &  25         & 0           & -1.16       &   0         & 1           & 0           & B          \\\\\n",
       "\t  2.5367549  & 7853.9816   & 65449.84695 & 0.1200000   & 17.80000    & 61.10000    & 2.54        &  11.0000    & 117         & 0           &  0.00       &  72         & 0           & 1           & B          \\\\\n",
       "\t  0.5661324  & 6126.1057   & 35342.91735 & 0.1733333   & 17.80000    & 61.10000    & 2.54        &  11.0000    & 117         & 0           &  0.00       &  25         & 0           & 1           & B          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Conc | SA | V | SA/V | Th-SC | Th-Ep | Th-T | Fol-Den | Fol-Dia | Enh | Kow | ConAng | Kow-sw | ConAng-sw | LayerQ |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  7.3957868  | 3848.4510   | 22449.29750 | 0.1714286   | 17.80000    | 61.10000    | 2.54        |  11.0000    | 200         | 0           |  0.00       |  72         | 0           | 1           | A           |\n",
       "| 33.5190452  |  706.8583   |  1767.14587 | 0.4000000   | 15.58889    | 67.54286    | 2.48        | 264.8333    |  97         | 0           |  0.00       | 151         | 0           | 1           | B           |\n",
       "| 10.0000000  | 4901.6699   | 32269.32709 | 0.1518987   | 17.82000    | 61.10000    | 2.54        |  11.0000    | 117         | 0           | -1.16       |   0         | 1           | 0           | B           |\n",
       "|  1.0000000  |   66.4761   |    50.96501 | 1.3043478   | 16.60000    | 32.00000    | 2.09        | 289.0000    |  25         | 0           | -1.16       |   0         | 1           | 0           | B           |\n",
       "|  2.5367549  | 7853.9816   | 65449.84695 | 0.1200000   | 17.80000    | 61.10000    | 2.54        |  11.0000    | 117         | 0           |  0.00       |  72         | 0           | 1           | B           |\n",
       "|  0.5661324  | 6126.1057   | 35342.91735 | 0.1733333   | 17.80000    | 61.10000    | 2.54        |  11.0000    | 117         | 0           |  0.00       |  25         | 0           | 1           | B           |\n",
       "\n"
      ],
      "text/plain": [
       "  Conc       SA        V           SA/V      Th-SC    Th-Ep    Th-T Fol-Den \n",
       "1  7.3957868 3848.4510 22449.29750 0.1714286 17.80000 61.10000 2.54  11.0000\n",
       "2 33.5190452  706.8583  1767.14587 0.4000000 15.58889 67.54286 2.48 264.8333\n",
       "3 10.0000000 4901.6699 32269.32709 0.1518987 17.82000 61.10000 2.54  11.0000\n",
       "4  1.0000000   66.4761    50.96501 1.3043478 16.60000 32.00000 2.09 289.0000\n",
       "5  2.5367549 7853.9816 65449.84695 0.1200000 17.80000 61.10000 2.54  11.0000\n",
       "6  0.5661324 6126.1057 35342.91735 0.1733333 17.80000 61.10000 2.54  11.0000\n",
       "  Fol-Dia Enh Kow   ConAng Kow-sw ConAng-sw LayerQ\n",
       "1 200     0    0.00  72    0      1         A     \n",
       "2  97     0    0.00 151    0      1         B     \n",
       "3 117     0   -1.16   0    1      0         B     \n",
       "4  25     0   -1.16   0    1      0         B     \n",
       "5 117     0    0.00  72    0      1         B     \n",
       "6 117     0    0.00  25    0      1         B     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "method_file_name = \"k_means\"\n",
    "#method_file_name = \"random\"\n",
    "#method_file_name = \"som\"\n",
    "#method_file_name = \"kenndard_stone\"\n",
    "data_file_path = paste(\"data/\",method_file_name,\".xlsx\",sep=\"\")\n",
    "\n",
    "train_df <- read.xlsx(data_file_path, sheet = 1) # training dataset\n",
    "validation_df <- read.xlsx(data_file_path, sheet = 2) # validation dataset\n",
    "test_df <- read.xlsx(data_file_path, sheet = 3) # testing dataset\n",
    "\n",
    "\n",
    "#features names\n",
    "features <- colnames(train_df)[-ncol(train_df)]\n",
    "#labels\n",
    "label <- colnames(train_df)[ncol(train_df)-1]\n",
    "labelQ <- colnames(train_df)[ncol(train_df)]\n",
    "\n",
    "#removing the duplicate column\n",
    "train_df[label] <- NULL\n",
    "validation_df[label] <- NULL\n",
    "test_df[label] <- NULL\n",
    "features <- c('SA/V','Th-SC','Th-Ep','Th-T','Fol-Den','Fol-Dia','Kow','ConAng','Kow-sw')\n",
    "#features <- colnames(train_df)[-ncol(train_df)]\n",
    "#changing the label character to factor\n",
    "train_df[labelQ] <- as.factor(train_df[,labelQ])\n",
    "validation_df[labelQ] <- as.factor(validation_df[,labelQ])\n",
    "test_df[labelQ] <- as.factor(test_df[,labelQ])\n",
    "\n",
    "#train_df <- unique(train_df)\n",
    "#validation_df <- unique(validation_df)\n",
    "#test_df <- unique(test_df)\n",
    "\n",
    "head(train_df)\n",
    "head(validation_df)\n",
    "head(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valdiation_df <- rbind(train_df,validation_df)\n",
    "pca_train <- prcomp(train_valdiation_df[,features],center = TRUE,  scale = TRUE, rank. = 8)\n",
    "pca_trainX <- pca_train$x\n",
    "trainY <- train_valdiation_df[,labelQ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpKSVM <- list(type = \"Classification\", library = \"kernlab\", loop = NULL)\n",
    "lpKSVM$parameters <- data.frame(parameter = c(\"C\",\"sigma\"),\n",
    "                     class = rep(\"numeric\",2),\n",
    "                     label = c(\"C\",\"sigma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tuning <- expand.grid(\n",
    "  C =  0.16, #seq(28,30,1),\n",
    "  sigma = 1.09 #seq(2.5,2.8,.05)\n",
    ")\n",
    "lpKSVM$grid = grid_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpKSVM$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) { \n",
    "  kernlab::ksvm(\n",
    "    x = as.matrix(x), y = y,\n",
    "    kernel = \"rbfdot\",\n",
    "    type = \"kbb-svc\",\n",
    "    kpar = list(sigma = param$sigma),\n",
    "    C = param$C,\n",
    "    prob.model = classProbs,\n",
    "    ...\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict function for CARET's custom model testing\n",
    "lpKSVM$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)\n",
    "  kernlab::predict(modelFit, newdata)\n",
    "\n",
    "lpKSVM$levels <- function(x) kernlab::lev(x)\n",
    "\n",
    "lpKSVM$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)\n",
    "  kernlab::predict(modelFit, newdata, type = \"probabilities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train control object\n",
    "train_control <- caret::trainControl(\n",
    "  method = \"LOOCV\", # leave one out cross validation\n",
    "  verboseIter = TRUE,\n",
    "  allowParallel = TRUE  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Fold001: C=0.16, sigma=1.09 \n",
      "- Fold001: C=0.16, sigma=1.09 \n",
      "+ Fold002: C=0.16, sigma=1.09 \n",
      "- Fold002: C=0.16, sigma=1.09 \n",
      "+ Fold003: C=0.16, sigma=1.09 \n",
      "- Fold003: C=0.16, sigma=1.09 \n",
      "+ Fold004: C=0.16, sigma=1.09 \n",
      "- Fold004: C=0.16, sigma=1.09 \n",
      "+ Fold005: C=0.16, sigma=1.09 \n",
      "- Fold005: C=0.16, sigma=1.09 \n",
      "+ Fold006: C=0.16, sigma=1.09 \n",
      "- Fold006: C=0.16, sigma=1.09 \n",
      "+ Fold007: C=0.16, sigma=1.09 \n",
      "- Fold007: C=0.16, sigma=1.09 \n",
      "+ Fold008: C=0.16, sigma=1.09 \n",
      "- Fold008: C=0.16, sigma=1.09 \n",
      "+ Fold009: C=0.16, sigma=1.09 \n",
      "- Fold009: C=0.16, sigma=1.09 \n",
      "+ Fold010: C=0.16, sigma=1.09 \n",
      "- Fold010: C=0.16, sigma=1.09 \n",
      "+ Fold011: C=0.16, sigma=1.09 \n",
      "- Fold011: C=0.16, sigma=1.09 \n",
      "+ Fold012: C=0.16, sigma=1.09 \n",
      "- Fold012: C=0.16, sigma=1.09 \n",
      "+ Fold013: C=0.16, sigma=1.09 \n",
      "- Fold013: C=0.16, sigma=1.09 \n",
      "+ Fold014: C=0.16, sigma=1.09 \n",
      "- Fold014: C=0.16, sigma=1.09 \n",
      "+ Fold015: C=0.16, sigma=1.09 \n",
      "- Fold015: C=0.16, sigma=1.09 \n",
      "+ Fold016: C=0.16, sigma=1.09 \n",
      "- Fold016: C=0.16, sigma=1.09 \n",
      "+ Fold017: C=0.16, sigma=1.09 \n",
      "- Fold017: C=0.16, sigma=1.09 \n",
      "+ Fold018: C=0.16, sigma=1.09 \n",
      "- Fold018: C=0.16, sigma=1.09 \n",
      "+ Fold019: C=0.16, sigma=1.09 \n",
      "- Fold019: C=0.16, sigma=1.09 \n",
      "+ Fold020: C=0.16, sigma=1.09 \n",
      "- Fold020: C=0.16, sigma=1.09 \n",
      "+ Fold021: C=0.16, sigma=1.09 \n",
      "- Fold021: C=0.16, sigma=1.09 \n",
      "+ Fold022: C=0.16, sigma=1.09 \n",
      "- Fold022: C=0.16, sigma=1.09 \n",
      "+ Fold023: C=0.16, sigma=1.09 \n",
      "- Fold023: C=0.16, sigma=1.09 \n",
      "+ Fold024: C=0.16, sigma=1.09 \n",
      "- Fold024: C=0.16, sigma=1.09 \n",
      "+ Fold025: C=0.16, sigma=1.09 \n",
      "- Fold025: C=0.16, sigma=1.09 \n",
      "+ Fold026: C=0.16, sigma=1.09 \n",
      "- Fold026: C=0.16, sigma=1.09 \n",
      "+ Fold027: C=0.16, sigma=1.09 \n",
      "- Fold027: C=0.16, sigma=1.09 \n",
      "+ Fold028: C=0.16, sigma=1.09 \n",
      "- Fold028: C=0.16, sigma=1.09 \n",
      "+ Fold029: C=0.16, sigma=1.09 \n",
      "- Fold029: C=0.16, sigma=1.09 \n",
      "+ Fold030: C=0.16, sigma=1.09 \n",
      "- Fold030: C=0.16, sigma=1.09 \n",
      "+ Fold031: C=0.16, sigma=1.09 \n",
      "- Fold031: C=0.16, sigma=1.09 \n",
      "+ Fold032: C=0.16, sigma=1.09 \n",
      "- Fold032: C=0.16, sigma=1.09 \n",
      "+ Fold033: C=0.16, sigma=1.09 \n",
      "- Fold033: C=0.16, sigma=1.09 \n",
      "+ Fold034: C=0.16, sigma=1.09 \n",
      "- Fold034: C=0.16, sigma=1.09 \n",
      "+ Fold035: C=0.16, sigma=1.09 \n",
      "- Fold035: C=0.16, sigma=1.09 \n",
      "+ Fold036: C=0.16, sigma=1.09 \n",
      "- Fold036: C=0.16, sigma=1.09 \n",
      "+ Fold037: C=0.16, sigma=1.09 \n",
      "- Fold037: C=0.16, sigma=1.09 \n",
      "+ Fold038: C=0.16, sigma=1.09 \n",
      "- Fold038: C=0.16, sigma=1.09 \n",
      "+ Fold039: C=0.16, sigma=1.09 \n",
      "- Fold039: C=0.16, sigma=1.09 \n",
      "+ Fold040: C=0.16, sigma=1.09 \n",
      "- Fold040: C=0.16, sigma=1.09 \n",
      "+ Fold041: C=0.16, sigma=1.09 \n",
      "- Fold041: C=0.16, sigma=1.09 \n",
      "+ Fold042: C=0.16, sigma=1.09 \n",
      "- Fold042: C=0.16, sigma=1.09 \n",
      "+ Fold043: C=0.16, sigma=1.09 \n",
      "- Fold043: C=0.16, sigma=1.09 \n",
      "+ Fold044: C=0.16, sigma=1.09 \n",
      "- Fold044: C=0.16, sigma=1.09 \n",
      "+ Fold045: C=0.16, sigma=1.09 \n",
      "- Fold045: C=0.16, sigma=1.09 \n",
      "+ Fold046: C=0.16, sigma=1.09 \n",
      "- Fold046: C=0.16, sigma=1.09 \n",
      "+ Fold047: C=0.16, sigma=1.09 \n",
      "- Fold047: C=0.16, sigma=1.09 \n",
      "+ Fold048: C=0.16, sigma=1.09 \n",
      "- Fold048: C=0.16, sigma=1.09 \n",
      "+ Fold049: C=0.16, sigma=1.09 \n",
      "- Fold049: C=0.16, sigma=1.09 \n",
      "+ Fold050: C=0.16, sigma=1.09 \n",
      "- Fold050: C=0.16, sigma=1.09 \n",
      "+ Fold051: C=0.16, sigma=1.09 \n",
      "- Fold051: C=0.16, sigma=1.09 \n",
      "+ Fold052: C=0.16, sigma=1.09 \n",
      "- Fold052: C=0.16, sigma=1.09 \n",
      "+ Fold053: C=0.16, sigma=1.09 \n",
      "- Fold053: C=0.16, sigma=1.09 \n",
      "+ Fold054: C=0.16, sigma=1.09 \n",
      "- Fold054: C=0.16, sigma=1.09 \n",
      "+ Fold055: C=0.16, sigma=1.09 \n",
      "- Fold055: C=0.16, sigma=1.09 \n",
      "+ Fold056: C=0.16, sigma=1.09 \n",
      "- Fold056: C=0.16, sigma=1.09 \n",
      "+ Fold057: C=0.16, sigma=1.09 \n",
      "- Fold057: C=0.16, sigma=1.09 \n",
      "+ Fold058: C=0.16, sigma=1.09 \n",
      "- Fold058: C=0.16, sigma=1.09 \n",
      "+ Fold059: C=0.16, sigma=1.09 \n",
      "- Fold059: C=0.16, sigma=1.09 \n",
      "+ Fold060: C=0.16, sigma=1.09 \n",
      "- Fold060: C=0.16, sigma=1.09 \n",
      "+ Fold061: C=0.16, sigma=1.09 \n",
      "- Fold061: C=0.16, sigma=1.09 \n",
      "+ Fold062: C=0.16, sigma=1.09 \n",
      "- Fold062: C=0.16, sigma=1.09 \n",
      "+ Fold063: C=0.16, sigma=1.09 \n",
      "- Fold063: C=0.16, sigma=1.09 \n",
      "+ Fold064: C=0.16, sigma=1.09 \n",
      "- Fold064: C=0.16, sigma=1.09 \n",
      "+ Fold065: C=0.16, sigma=1.09 \n",
      "- Fold065: C=0.16, sigma=1.09 \n",
      "+ Fold066: C=0.16, sigma=1.09 \n",
      "- Fold066: C=0.16, sigma=1.09 \n",
      "+ Fold067: C=0.16, sigma=1.09 \n",
      "- Fold067: C=0.16, sigma=1.09 \n",
      "+ Fold068: C=0.16, sigma=1.09 \n",
      "- Fold068: C=0.16, sigma=1.09 \n",
      "+ Fold069: C=0.16, sigma=1.09 \n",
      "- Fold069: C=0.16, sigma=1.09 \n",
      "+ Fold070: C=0.16, sigma=1.09 \n",
      "- Fold070: C=0.16, sigma=1.09 \n",
      "+ Fold071: C=0.16, sigma=1.09 \n",
      "- Fold071: C=0.16, sigma=1.09 \n",
      "+ Fold072: C=0.16, sigma=1.09 \n",
      "- Fold072: C=0.16, sigma=1.09 \n",
      "+ Fold073: C=0.16, sigma=1.09 \n",
      "- Fold073: C=0.16, sigma=1.09 \n",
      "+ Fold074: C=0.16, sigma=1.09 \n",
      "- Fold074: C=0.16, sigma=1.09 \n",
      "+ Fold075: C=0.16, sigma=1.09 \n",
      "- Fold075: C=0.16, sigma=1.09 \n",
      "+ Fold076: C=0.16, sigma=1.09 \n",
      "- Fold076: C=0.16, sigma=1.09 \n",
      "+ Fold077: C=0.16, sigma=1.09 \n",
      "- Fold077: C=0.16, sigma=1.09 \n",
      "+ Fold078: C=0.16, sigma=1.09 \n",
      "- Fold078: C=0.16, sigma=1.09 \n",
      "+ Fold079: C=0.16, sigma=1.09 \n",
      "- Fold079: C=0.16, sigma=1.09 \n",
      "+ Fold080: C=0.16, sigma=1.09 \n",
      "- Fold080: C=0.16, sigma=1.09 \n",
      "+ Fold081: C=0.16, sigma=1.09 \n",
      "- Fold081: C=0.16, sigma=1.09 \n",
      "+ Fold082: C=0.16, sigma=1.09 \n",
      "- Fold082: C=0.16, sigma=1.09 \n",
      "+ Fold083: C=0.16, sigma=1.09 \n",
      "- Fold083: C=0.16, sigma=1.09 \n",
      "+ Fold084: C=0.16, sigma=1.09 \n",
      "- Fold084: C=0.16, sigma=1.09 \n",
      "+ Fold085: C=0.16, sigma=1.09 \n",
      "- Fold085: C=0.16, sigma=1.09 \n",
      "+ Fold086: C=0.16, sigma=1.09 \n",
      "- Fold086: C=0.16, sigma=1.09 \n",
      "+ Fold087: C=0.16, sigma=1.09 \n",
      "- Fold087: C=0.16, sigma=1.09 \n",
      "+ Fold088: C=0.16, sigma=1.09 \n",
      "- Fold088: C=0.16, sigma=1.09 \n",
      "+ Fold089: C=0.16, sigma=1.09 \n",
      "- Fold089: C=0.16, sigma=1.09 \n",
      "+ Fold090: C=0.16, sigma=1.09 \n",
      "- Fold090: C=0.16, sigma=1.09 \n",
      "+ Fold091: C=0.16, sigma=1.09 \n",
      "- Fold091: C=0.16, sigma=1.09 \n",
      "+ Fold092: C=0.16, sigma=1.09 \n",
      "- Fold092: C=0.16, sigma=1.09 \n",
      "+ Fold093: C=0.16, sigma=1.09 \n",
      "- Fold093: C=0.16, sigma=1.09 \n",
      "+ Fold094: C=0.16, sigma=1.09 \n",
      "- Fold094: C=0.16, sigma=1.09 \n",
      "+ Fold095: C=0.16, sigma=1.09 \n",
      "- Fold095: C=0.16, sigma=1.09 \n",
      "+ Fold096: C=0.16, sigma=1.09 \n",
      "- Fold096: C=0.16, sigma=1.09 \n",
      "+ Fold097: C=0.16, sigma=1.09 \n",
      "- Fold097: C=0.16, sigma=1.09 \n",
      "+ Fold098: C=0.16, sigma=1.09 \n",
      "- Fold098: C=0.16, sigma=1.09 \n",
      "+ Fold099: C=0.16, sigma=1.09 \n",
      "- Fold099: C=0.16, sigma=1.09 \n",
      "+ Fold100: C=0.16, sigma=1.09 \n",
      "- Fold100: C=0.16, sigma=1.09 \n",
      "+ Fold101: C=0.16, sigma=1.09 \n",
      "- Fold101: C=0.16, sigma=1.09 \n",
      "+ Fold102: C=0.16, sigma=1.09 \n",
      "- Fold102: C=0.16, sigma=1.09 \n",
      "+ Fold103: C=0.16, sigma=1.09 \n",
      "- Fold103: C=0.16, sigma=1.09 \n",
      "+ Fold104: C=0.16, sigma=1.09 \n",
      "- Fold104: C=0.16, sigma=1.09 \n",
      "+ Fold105: C=0.16, sigma=1.09 \n",
      "- Fold105: C=0.16, sigma=1.09 \n",
      "+ Fold106: C=0.16, sigma=1.09 \n",
      "- Fold106: C=0.16, sigma=1.09 \n",
      "+ Fold107: C=0.16, sigma=1.09 \n",
      "- Fold107: C=0.16, sigma=1.09 \n",
      "+ Fold108: C=0.16, sigma=1.09 \n",
      "- Fold108: C=0.16, sigma=1.09 \n",
      "+ Fold109: C=0.16, sigma=1.09 \n",
      "- Fold109: C=0.16, sigma=1.09 \n",
      "+ Fold110: C=0.16, sigma=1.09 \n",
      "- Fold110: C=0.16, sigma=1.09 \n",
      "+ Fold111: C=0.16, sigma=1.09 \n",
      "- Fold111: C=0.16, sigma=1.09 \n",
      "+ Fold112: C=0.16, sigma=1.09 \n",
      "- Fold112: C=0.16, sigma=1.09 \n",
      "+ Fold113: C=0.16, sigma=1.09 \n",
      "- Fold113: C=0.16, sigma=1.09 \n",
      "+ Fold114: C=0.16, sigma=1.09 \n",
      "- Fold114: C=0.16, sigma=1.09 \n",
      "+ Fold115: C=0.16, sigma=1.09 \n",
      "- Fold115: C=0.16, sigma=1.09 \n",
      "+ Fold116: C=0.16, sigma=1.09 \n",
      "- Fold116: C=0.16, sigma=1.09 \n",
      "+ Fold117: C=0.16, sigma=1.09 \n",
      "- Fold117: C=0.16, sigma=1.09 \n",
      "+ Fold118: C=0.16, sigma=1.09 \n",
      "- Fold118: C=0.16, sigma=1.09 \n",
      "+ Fold119: C=0.16, sigma=1.09 \n",
      "- Fold119: C=0.16, sigma=1.09 \n",
      "+ Fold120: C=0.16, sigma=1.09 \n",
      "- Fold120: C=0.16, sigma=1.09 \n",
      "+ Fold121: C=0.16, sigma=1.09 \n",
      "- Fold121: C=0.16, sigma=1.09 \n",
      "+ Fold122: C=0.16, sigma=1.09 \n",
      "- Fold122: C=0.16, sigma=1.09 \n",
      "+ Fold123: C=0.16, sigma=1.09 \n",
      "- Fold123: C=0.16, sigma=1.09 \n",
      "+ Fold124: C=0.16, sigma=1.09 \n",
      "- Fold124: C=0.16, sigma=1.09 \n",
      "+ Fold125: C=0.16, sigma=1.09 \n",
      "- Fold125: C=0.16, sigma=1.09 \n",
      "+ Fold126: C=0.16, sigma=1.09 \n",
      "- Fold126: C=0.16, sigma=1.09 \n",
      "+ Fold127: C=0.16, sigma=1.09 \n",
      "- Fold127: C=0.16, sigma=1.09 \n",
      "+ Fold128: C=0.16, sigma=1.09 \n",
      "- Fold128: C=0.16, sigma=1.09 \n",
      "+ Fold129: C=0.16, sigma=1.09 \n",
      "- Fold129: C=0.16, sigma=1.09 \n",
      "+ Fold130: C=0.16, sigma=1.09 \n",
      "- Fold130: C=0.16, sigma=1.09 \n",
      "+ Fold131: C=0.16, sigma=1.09 \n",
      "- Fold131: C=0.16, sigma=1.09 \n",
      "+ Fold132: C=0.16, sigma=1.09 \n",
      "- Fold132: C=0.16, sigma=1.09 \n",
      "+ Fold133: C=0.16, sigma=1.09 \n",
      "- Fold133: C=0.16, sigma=1.09 \n",
      "+ Fold134: C=0.16, sigma=1.09 \n",
      "- Fold134: C=0.16, sigma=1.09 \n",
      "+ Fold135: C=0.16, sigma=1.09 \n",
      "- Fold135: C=0.16, sigma=1.09 \n",
      "+ Fold136: C=0.16, sigma=1.09 \n",
      "- Fold136: C=0.16, sigma=1.09 \n",
      "+ Fold137: C=0.16, sigma=1.09 \n",
      "- Fold137: C=0.16, sigma=1.09 \n",
      "+ Fold138: C=0.16, sigma=1.09 \n",
      "- Fold138: C=0.16, sigma=1.09 \n",
      "+ Fold139: C=0.16, sigma=1.09 \n",
      "- Fold139: C=0.16, sigma=1.09 \n",
      "+ Fold140: C=0.16, sigma=1.09 \n",
      "- Fold140: C=0.16, sigma=1.09 \n",
      "+ Fold141: C=0.16, sigma=1.09 \n",
      "- Fold141: C=0.16, sigma=1.09 \n",
      "+ Fold142: C=0.16, sigma=1.09 \n",
      "- Fold142: C=0.16, sigma=1.09 \n",
      "+ Fold143: C=0.16, sigma=1.09 \n",
      "- Fold143: C=0.16, sigma=1.09 \n",
      "Aggregating results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting final model on full training set\n"
     ]
    }
   ],
   "source": [
    "# searching for parameters\n",
    "ksvm_base <- caret::train(\n",
    "  x = pca_trainX,\n",
    "  y = factor(trainY,labels = c(\"A\",\"B\",\"C\",\"D\",\"E\")),\n",
    "  trControl = train_control,\n",
    "  tuneGrid = grid_tuning,\n",
    "  method = lpKSVM,\n",
    "  #index = 1:nrow(pca_trainX),\n",
    "  #indexOut = nrow(pca_trainX)+(1:nrow(pca_validationX))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.16"
      ],
      "text/latex": [
       "0.16"
      ],
      "text/markdown": [
       "0.16"
      ],
      "text/plain": [
       "[1] 0.16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1.09"
      ],
      "text/latex": [
       "1.09"
      ],
      "text/markdown": [
       "1.09"
      ],
      "text/plain": [
       "[1] 1.09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ksvm_model  <- ksvm(x = pca_trainX, y = trainY, type = \"spoc-svc\",C = ksvm_base$bestTune$C, kpar = list(sigma = ksvm_base$bestTune$sigma))\n",
    "ksvm_base$bestTune$C\n",
    "ksvm_base$bestTune$sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Checking the performance on the training set\"\n",
      "[1] 0.09090909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            predictions\n",
       "observations  A  B  C  D  E\n",
       "           A  2  2  1  0  0\n",
       "           B  0 60  6  0  0\n",
       "           C  0  2 64  0  0\n",
       "           D  0  0  1  2  0\n",
       "           E  0  1  0  0  2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAANlBMVEUAAAAzMzNNTU1oaGh8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\nsPgALD7/A8/s6poHE6Z/AAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Checking the performance on the training set\")\n",
    "pred_labels <- predict(ksvm_model,pca_trainX)\n",
    "print(sum(as.numeric(pred_labels) != (as.numeric(trainY)))/length(trainY))\n",
    "\n",
    "\n",
    "options(repr.plot.width=4, repr.plot.height=4)\n",
    "df.train = data.frame(observations = as.factor(trainY), predictions = as.factor(pred_labels) )\n",
    "table(df.train)\n",
    "plotTrainingSet <- ggplot(data = df.train,aes(x=observations,y=predictions)) + geom_jitter(width=0.1,height=0.1)\n",
    "plotTrainingSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  A  B  C  D  E\n",
       "         A  2  2  1  0  0\n",
       "         B  0 60  6  0  0\n",
       "         C  0  2 64  0  0\n",
       "         D  0  0  1  2  0\n",
       "         E  0  1  0  0  2\n",
       "\n",
       "Overall Statistics\n",
       "                                          \n",
       "               Accuracy : 0.9091          \n",
       "                 95% CI : (0.8496, 0.9507)\n",
       "    No Information Rate : 0.5035          \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.8367          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : NA              \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: A Class: B Class: C Class: D Class: E\n",
       "Sensitivity           1.00000   0.9231   0.8889  1.00000  1.00000\n",
       "Specificity           0.97872   0.9231   0.9718  0.99291  0.99291\n",
       "Pos Pred Value        0.40000   0.9091   0.9697  0.66667  0.66667\n",
       "Neg Pred Value        1.00000   0.9351   0.8961  1.00000  1.00000\n",
       "Prevalence            0.01399   0.4545   0.5035  0.01399  0.01399\n",
       "Detection Rate        0.01399   0.4196   0.4476  0.01399  0.01399\n",
       "Detection Prevalence  0.03497   0.4615   0.4615  0.02098  0.02098\n",
       "Balanced Accuracy     0.98936   0.9231   0.9304  0.99645  0.99645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(data = df.train$observations, reference = df.train$predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Checking the performance on the testing set\"\n",
      "[1] 0.125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            predictions\n",
       "observations  A  B  C  D  E\n",
       "           A  1  0  0  0  0\n",
       "           B  0 14  2  0  0\n",
       "           C  0  2 11  0  0\n",
       "           D  0  0  0  1  0\n",
       "           E  0  0  0  0  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAANlBMVEUAAAAzMzNNTU1oaGh8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\nR2D4CAyf/wGafRHsT47RGAAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Checking the performance on the testing set\")\n",
    "testY = test_df[,labelQ]\n",
    "pca_testX <- predict(pca_train,test_df)\n",
    "pred_labels <- predict(ksvm_model,pca_testX)\n",
    "print(sum(as.numeric(pred_labels) != (as.numeric(testY)))/length(testY))\n",
    "\n",
    "df.test = data.frame(observations = as.factor(testY), predictions = (pred_labels) )\n",
    "plotTestingSet <- ggplot(data = df.test,aes(x=observations,y=predictions)) + geom_jitter(width=0.1,height=0.1)\n",
    "plotTestingSet\n",
    "table(df.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  A  B  C  D  E\n",
       "         A  1  0  0  0  0\n",
       "         B  0 14  2  0  0\n",
       "         C  0  2 11  0  0\n",
       "         D  0  0  0  1  0\n",
       "         E  0  0  0  0  1\n",
       "\n",
       "Overall Statistics\n",
       "                                          \n",
       "               Accuracy : 0.875           \n",
       "                 95% CI : (0.7101, 0.9649)\n",
       "    No Information Rate : 0.5             \n",
       "    P-Value [Acc > NIR] : 9.651e-06       \n",
       "                                          \n",
       "                  Kappa : 0.7852          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : NA              \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: A Class: B Class: C Class: D Class: E\n",
       "Sensitivity           1.00000   0.8750   0.8462  1.00000  1.00000\n",
       "Specificity           1.00000   0.8750   0.8947  1.00000  1.00000\n",
       "Pos Pred Value        1.00000   0.8750   0.8462  1.00000  1.00000\n",
       "Neg Pred Value        1.00000   0.8750   0.8947  1.00000  1.00000\n",
       "Prevalence            0.03125   0.5000   0.4062  0.03125  0.03125\n",
       "Detection Rate        0.03125   0.4375   0.3438  0.03125  0.03125\n",
       "Detection Prevalence  0.03125   0.5000   0.4062  0.03125  0.03125\n",
       "Balanced Accuracy     1.00000   0.8750   0.8704  1.00000  1.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(data = df.test$observations, reference = df.test$predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
